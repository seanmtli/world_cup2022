---
title: "World Cup 2022"
author: "Sean Li, Brian Janger, Aaditya Warrier, Christina Yoh"
date: '2022-12-03'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      results = FALSE)
```

Methodology: 
Using historical data and group stage matches individual match up to the final 16 (because we know these matchups will occur) 
Based on this data, we will calculate win probabilities, loss probabilities, and expected score 
Based on individual matches in the group stage up to round of 16, we will calculate who wins top of their group/2nd etc. 

Model: 
Use a probabilistic model, because sports betters want to know probabilities 
Poisson GLM, can use lasso
Monte Carlo 

We are predicting the goal-line (MUST BE ABSOLUTE VALUE CAUSE POISSON WILL NOT WORK OTHERWISE) for each match upto round of 16 using a Poisson GLM that takes home stats and away stats into account, as well as individual team rosters 

Will need to make two diff models for home and away because of negative value restriction

## FINAL WRITEUP

```{r}
library(tidyverse)
#library(DescTools)
library(glmnet)
library(extraDistr)
data("d.countries")
source("biv-pois-functions/lm.bp.R")
source("biv-pois-functions/bivpois.table.R")
source("biv-pois-functions/newnamesbeta.R")
source("biv-pois-functions/pbivpois.R")
source("biv-pois-functions/simple.bp.R")
source("biv-pois-functions/splitbeta.R")
int_matches <- read_csv("data/international_matches.csv")
qatar_teams <- read_delim("data/Qatar2022-teams.csv", delim = ";")
matches_sched <- read_delim("data/matches_schedule.csv", delim = ";")
final_roster_data <- read_csv("data/final_roster_data.csv")
worldcup_2022_matches<-read_csv("data/Fifa_world_cup_matches.csv")
qatar_groupstage_teams <- read.csv("data/FIFA2022_GroupStageTeams.csv")
matches_results_2022 <- read.csv("data/matches_results.csv")
cleaned_matches <- read_csv("data/cleaned_matches.csv")
```




#Introduction 

The FIFA World Cup is the most important international soccer tournament in the world, bringing in over 5 billion projected viewers across the 29 day tournament. It is held every four years and brings together the best national teams from countries around the globe to compete for the title of world champions. Not only does the World Cup provide an opportunity for players to showcase their skills on the biggest stage, it also generates a huge amount of interest and excitement (and thus revenues) and provides people from all over the world an opportunity to come together and celebrate their love of soccer, fostering a sense of global unity and understanding.

For a subset of the followers of the World Cup, sports betting has become a prominent part of the experience. The sports betting industry is a large and growing market that involves people placing bets on the outcome of various sports events. This can include bets on individual games or on the overall results of a season or tournament. According to Bloomberg, a total of $35 billion will be wagered on the 2022 FIFA World Cup, a 65% increase on the previous World Cup. 

An integral part of sports betting is the usage of statistics, as it can provide valuable information about the likelihood of certain outcomes in a given game or match. By using statistics, bettors can analyze the true risk on various bets (as opposed to a sportsbook's "odds") and make more informed decisions about which bets to place, giving bettors a better chance of winning and achieving profitable returns.

In short, the goal of our project is to build a predictive model for the 2022 World Cup games using historical international football results and FIFA team rankings in order to provide sports bettors valuable information about the probability of certain outcomes in this year's World Cup. We hope predict goal line bets (point spread/goal differential) as well as 3 way money-line (draw, home win, and away win) bets from the group stage, comparing the odds of respective matches with the odds given by sportsbooks to determine which bets are more likely to be profitable then the odds say.

The dataset we use is a set of thousands of international soccer matches from June 2002 to June 2021, with metrics including team FIFA rank, team FIFA points, match results, offense/defense/midfield score metrics and more. We will first use a Poisson regression model on both home and away team scores to predict score distribution for each team respectively with a lasso penalty to select significant predictor variables and reduce collinearity. Using these relevant predictors, we will then fit a bivariate Poisson model that takes into account the dependency between home and away team goal distributions. Since we have a small number of goals, Poisson regression makes sense as it is intended for response variables that take on small, positive values. Getting results that are probabilistic distributions are important in our case because sports betters are interested in the distribution of results in order to be able to quantify their risk. 


#Exploratory Data Analysis 

```{r}
# Making new variables, keeping torunament matches only
cups_only <- int_matches %>%
  filter(!str_detect(tournament, "Friendly|qualification"), format(date, "%Y") >= 2000) %>%
  select(-home_team_goalkeeper_score, away_team_goalkeeper_score) %>%
  mutate(rank_differential = away_team_fifa_rank - home_team_fifa_rank, #away - home so positive rank differential means home team is paper
         offense_differential = home_team_mean_offense_score - away_team_mean_offense_score,
         defense_differential = home_team_mean_defense_score - away_team_mean_defense_score,
         midfield_differential = home_team_mean_midfield_score - away_team_mean_midfield_score,
         points_differential = home_team_total_fifa_points - away_team_total_fifa_points,
         year = as.numeric(format(date, "%Y"))) 

cups_only_nona <- na.omit(cups_only)

```

```{r}
cups_only_nona <- cups_only_nona%>%
  mutate(goals_differential = home_team_score - away_team_score,
         avg_team_differential = (offense_differential + defense_differential + midfield_differential)/3 )

cups_only_nona
```

To start, we examine the distribution of home and away team scores in each match. The plots below are right skewed, with home teams and away teams both peaking at around 1 goal in a match, then decreasing exponentially up to around 7 goals a match. 

```{r}
par(mfrow=c(1,2))

ggplot(data = cups_only_nona) +
  geom_histogram(mapping = aes(x = home_team_score), binwidth = 0.5)

ggplot(data = cups_only_nona) +
  geom_histogram(mapping = aes(x = away_team_score), binwidth = 0.5)
```

Next, we examine the distribution of goal differentials. From this we can see that the distribution of goal_differentials is relatively normal and centered around 0, which indicates that most matches end up in a tie, followed by having a 1 goal difference, and has a smaller probability with higher goal differentials which makes sense. 

```{r}
ggplot(data = cups_only_nona) +
  geom_histogram(mapping = aes(x = goals_differential), binwidth = 0.5)
```

There are some interesting findings when examining the distribution of goal differentials when compared to the rank differential. In this case, goal differential is the difference between home team score and away team score (home team score-away team score), and rank_differentials is the difference between away team rank and home team rank (away team rank - home team rank; thus, if this is positive it means the home team is 
ranked higher -lower number-  than the away team). We can see that there is a slight association between rank_differential and goals_differential; the more positive the rank_differential is, the greater the goal differential between the home and away team, meaning that a greater difference in rank is associated with a slighter greater difference in scores. However, we also observe that rank_differential has the greatest range when goal_differential is 0, which signals that the outcome of a tie is likely even for teams with very different ranks. 


```{r}
ggplot(data = cups_only_nona, mapping = aes(x =rank_differential, y =goals_differential)) + 
  geom_point()
```

Based on the previous observation, it seems as rank_differential might be a relevant factor when looking at the distribution of goals. Looking more into the metric of rank_differential, we observe that differences in rank plays into home_team_result (win, draw, or loss). We can observe than when the home team wins, the median of the rank_differential is around 10, which means that when the home team wins, it is ranked 10 spots higher (lower number) than the away team. On the other hand, when the home team loses, the median of the rank_differential is around -8, which means that the home team is ranked 8 spots lower (higher number) than the away team. It's interesting to note that in the instance of a draw, the home team is ranked slightly (around 1 spot) higher (lower number)  than the away team as well. However, we can also notice that there is quite a large overlap in the middle 50th percentile of rank_differential for all three results, and there are also instances of significant amount of outliers, which point us to the uncertainty of soccer matches. 

```{r}
ggplot(data = cups_only_nona, mapping = aes(x = rank_differential, y =home_team_result)) + 
   geom_boxplot()
```

Additionally, we are interested to see whether differentials in the players skills (defense score, midfield score, offense score, which are all 
taken as the 3-4 highest ranked players of the team in that position), has differing effects on the final home team result. However, from the plots below, we can observe that offense_differential, defense_differential, and midfield_differential all have a similar impact on the home team result, with a home team result of win having a median of a greater positive differential, a loss having a negative differential, and a home team result of a tie having a differential slightly greater than 0. Of all 3 metrics, midfield_differential seems to have the smallest IQR across home_team_result. 


```{r}
ggplot(data = cups_only_nona, mapping = aes(x = offense_differential, y =home_team_result)) + 
   geom_boxplot()
```
```{r}
ggplot(data = cups_only_nona, mapping = aes(x = defense_differential, y =home_team_result)) + 
   geom_boxplot()
```
```{r}
ggplot(data = cups_only_nona, mapping = aes(x = midfield_differential, y =home_team_result)) + 
   geom_boxplot()
```


```{r}
home_team_offense <- cups_only_nona%>%
  select(home_team,date, home_team_mean_offense_score)%>%
  rename(
    team = home_team, 
    offense_score = home_team_mean_offense_score
  )

away_team_offense <- cups_only_nona%>%
  select(away_team, date, away_team_mean_offense_score)%>%
  rename(
    team = away_team, 
    offense_score = away_team_mean_offense_score
  )

team_offense <-rbind(home_team_offense, away_team_offense)
  
#  merge(x=home_team_ranks,y=away_team_ranks, 
  #           by=c("team","date","fifa_rank"))
top_team_offense<- team_offense%>%
    arrange((team),desc(date)) %>%
    group_by(team)%>%
    slice(1) 

top_10_offense <- top_team_offense%>%
  arrange(desc(offense_score))%>%head(10)

```

```{r} 
home_team_midfield <- cups_only_nona%>%
  select(home_team,date, home_team_mean_midfield_score)%>%
  rename(
    team = home_team, 
    midfield_score = home_team_mean_midfield_score
  )

away_team_midfield <- cups_only_nona%>%
  select(away_team, date, away_team_mean_midfield_score)%>%
  rename(
    team = away_team, 
    midfield_score = away_team_mean_midfield_score
  )

team_midfield <-rbind(home_team_midfield, away_team_midfield)
  
top_team_midfield<- team_midfield%>%
    arrange((team),desc(date)) %>%
    group_by(team)%>%
    slice(1) 

top_10_midfield <- top_team_midfield%>%
  arrange(desc(midfield_score))%>%head(10)

```

```{r}
home_team_defense <- cups_only_nona%>%
  select(home_team,date, home_team_mean_defense_score)%>%
  rename(
    team = home_team, 
    defense_score = home_team_mean_defense_score
  )

away_team_defense <- cups_only_nona%>%
  select(away_team, date, away_team_mean_defense_score)%>%
  rename(
    team = away_team, 
    defense_score = away_team_mean_defense_score
  )

team_defense <-rbind(home_team_defense, away_team_defense)
  
#  merge(x=home_team_ranks,y=away_team_ranks, 
  #           by=c("team","date","fifa_rank"))
top_team_defense<- team_defense%>%
    arrange((team),desc(date)) %>%
    group_by(team)%>%
    slice(1) 

top_10_defense <- top_team_defense%>%
  arrange(desc(defense_score))%>%head(10)
```

```{r}
top_team_int<- full_join(top_team_defense,top_team_midfield, by = c("team", "date"))

top_team_all<-full_join(top_team_int, top_team_offense, by=c("team", "date"))

top_15_team<-top_team_all%>%
  mutate(average_team_score = (defense_score + midfield_score+offense_score)/3)%>%
  arrange(desc(average_team_score))%>%
  head(15)
  

top_15_team
```

In the visualization below, we can examine the defense score, midfield score, offense score, and average team score (taken as an average of defense, midfield, and offense score with equal weighting) for the 15 teams with the highest average team score at its most recent date of ranking. The defense and midfield scores are taken as the average FIFA game score of the 4 highest ranked defense and midfield players of the team, while the offense score is taken as the average FIFA game score of the 3 highest ranked attacking players of the team. We can observe that most of the top 15 teams are pretty consistent across their offense, midfield and defense scores, though one factor may be a slight strong suit for the team. 


```{r}
library(reshape2)
team_scores <- melt(top_15_team, id = c("team","date"))
ggplot(team_scores, aes(fill=variable, y=value, x=reorder(team,+value))) + 
    geom_bar(position="dodge", stat="identity")+labs(x="team",y="score")+
    coord_flip()
```



#MODELING 

```{r}
# DECENT UNIVARIATE MODELS???
# Making new variables, keeping torunament matches only
cups_only <- int_matches %>%
  filter(!str_detect(tournament, "Friendly|qualification"), format(date, "%Y") >= 2000) %>%
  select(-home_team_goalkeeper_score, away_team_goalkeeper_score) %>%
  mutate(rank_differential = home_team_fifa_rank - away_team_fifa_rank,
         offense_differential = home_team_mean_offense_score - away_team_mean_offense_score,
         defense_differential = home_team_mean_defense_score - away_team_mean_defense_score,
         midfield_differential = home_team_mean_midfield_score - away_team_mean_midfield_score,
         points_differential = home_team_total_fifa_points - away_team_total_fifa_points,
         year = as.numeric(format(date, "%Y")))  %>%
   filter(neutral_location == TRUE)

# Summarizing roster data 
sum_roster <- final_roster_data %>%
  mutate(Country =
           case_when(Country == "South Korea" ~ "Korea Republic",
                     Country == "United States" ~ "USA",
                     Country == "Iran" ~ "IR Iran",
                     Country == "Ivory Coast" ~ "Côte d'Ivoire",
                     Country == "North Korea" ~ "Korea DPR",
                     TRUE ~  Country)) %>%
  group_by(Country, year) %>%
  summarize(median_caps_home = mean(as.numeric(Caps), na.rm = TRUE))

roster_away <- sum_roster %>%
  rename(median_caps_away = median_caps_home)

# This merges roster data - must adds caps_differential to all models if using ------------------

# cups_only <- left_join(cups_only, sum_roster, by = c("year" = "year",
#                                               "home_team" = "Country")) %>%
#   left_join(roster_away, by = c("year" = "year",
#                                               "away_team" = "Country")) %>%
#   mutate(caps_differential = median_caps_home - median_caps_away)

# ----------------------------------------------------------------------------------------------

# Fitting UNIVARIATE models --------------------------------------------------------------------

# Building train and test set for CV
set.seed(1)
cups_only_nona <- na.omit(cups_only)
n <- nrow(cups_only_nona)


train_nums <- seq(1, 0.8* nrow(cups_only_nona), 1)

#all the X variables for test data
test_data = cups_only_nona[-train_nums, ] %>%
  select(rank_differential, offense_differential, defense_differential, midfield_differential,
         points_differential, neutral_location) # add cap_diff if using
#predict function needs a mat, makes categorical into dummy vars
mat = model.matrix(~., test_data)
# actual y - values
test_home <- cups_only_nona[-train_nums, "home_team_score"] %>%
  pull()
test_away <- cups_only_nona[-train_nums, "away_team_score"] %>% 
  pull()

train_data <- cups_only_nona[train_nums, ]


# Model equations 
home_x <- model.matrix(home_team_score ~ rank_differential + offense_differential + 
                         defense_differential + midfield_differential + 
         points_differential + neutral_location, 
                       data = train_data) # add cap_diff if using
away_x <- model.matrix(away_team_score ~  + rank_differential + offense_differential + 
                         defense_differential + midfield_differential + 
         points_differential + neutral_location, 
                       data = train_data) # add cap_diff if using

home_y <- train_data$home_team_score
away_y <- train_data$away_team_score


# Cross validating 
lambda_grid <- 10^seq(-2, 10, length.out = 5000)
home_model <- cv.glmnet(home_x, home_y, alpha = 1, 
                        lambda = lambda_grid, family = "poisson",
                        nfolds = 5)
away_model <- cv.glmnet(away_x, away_y, alpha = 1, lambda = lambda_grid, family = "poisson", 
                        nfolds = 5)

home_lambda <- home_model$lambda.min
away_lambda <- away_model$lambda.min


# Fitting final models

final_home <- glmnet(home_x, home_y, alpha = 1, lambda = home_lambda, family = "poisson")
final_away <- glmnet(away_x, away_y, alpha = 1, lambda = away_lambda, family = "poisson")

final_home$beta
final_away$beta

# Generating preds
home_preds <- predict(home_model, newx = mat, type = "response")
away_preds <- predict(away_model, newx = mat, type = "response")
```


```{r checking}
# SANITY CHECKS FOR ACCURACY
sqrt(mean((test_home - home_preds)^2))
sqrt(mean((test_away - away_preds)^2))

median(abs(test_home - home_preds))
median(abs(test_away - away_preds))


goalline_preds <- home_preds - away_preds

outcomes <- na.omit(cups_only)[-train_nums, "home_team_result"] 

outcomes %>%
  count(home_team_result)

```


```{r biv-pois-model-test, warning=FALSE}
biv_cups_only_nona <- cups_only_nona %>%
  mutate(shoot_out = ifelse(shoot_out == "Yes", 1, 0),
         neutral_location = ifelse(neutral_location == TRUE, 1, 0))

n <- nrow(biv_cups_only_nona)

# HOME FIELD COMPENSATION?

# set.seed(3)
# switch <- sample(1:n, 0.5*n)
# 
# biv_cups_only_nona <- biv_cups_only_nona %>%
#   mutate(hgoals_new  = NA, agoals_new = NA)
# 
# for(i in 1:n) {
#   if(i %in% switch) {
#     biv_cups_only_nona[i, "hgoals_new"] = biv_cups_only_nona[i, "away_team_score"]
#     biv_cups_only_nona[i, "agoals_new"] = biv_cups_only_nona[i, "home_team_score"]
#     biv_cups_only_nona[i, "offense_differential"] = - (biv_cups_only_nona[i, "offense_differential"])
#     biv_cups_only_nona[i, "defense_differential"] = - (biv_cups_only_nona[i, "defense_differential"])
#     biv_cups_only_nona[i, "midfield_differential"] = - (biv_cups_only_nona[i, "midfield_differential"])
#     biv_cups_only_nona[i, "points_differential"] = - (biv_cups_only_nona[i, "points_differential"])
#     biv_cups_only_nona[i, "rank_differential"] = - (biv_cups_only_nona[i, "rank_differential"])
#   }
#   else {
#     biv_cups_only_nona[i, "hgoals_new"] = biv_cups_only_nona[i, "home_team_score"]
#     biv_cups_only_nona[i, "agoals_new"] = biv_cups_only_nona[i, "away_team_score"]
#   }
# }


set.seed(3)

train_nums <- sample(1:n, size = 0.8*n)

test_home <- biv_cups_only_nona[-train_nums, "home_team_score"]
test_away <- biv_cups_only_nona[-train_nums, "away_team_score"]


td1 <- biv_cups_only_nona[-train_nums, ] %>%
         select(offense_differential, defense_differential,
                   midfield_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)
td2 <- biv_cups_only_nona[-train_nums, ] %>%
         select(offense_differential, defense_differential,
                    midfield_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)
td3 <- biv_cups_only_nona[-train_nums, ] %>%
         select(offense_differential , defense_differential,
                    midfield_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)



test_home <- biv_cups_only_nona[-train_nums, "home_team_score"] %>%
  pull()
test_away <- biv_cups_only_nona[-train_nums, "away_team_score"] %>% 
  pull()

train_data_biv <- biv_cups_only_nona[train_nums, ]


#not split... make train data
fin_mod <- lm.bp(l1 = home_team_score~ 
                   offense_differential + defense_differential +
                    midfield_differential,
                 l2 = away_team_score~ offense_differential  + defense_differential +
                    midfield_differential,
                 l3 = ~ offense_differential  + defense_differential +
                   midfield_differential, 
                 data = train_data_biv)


# ok multiply
final_lambdas <- tibble(lambda_1 = exp(as.matrix(td1) %*% as.matrix(fin_mod$beta1)),
                        lambda_2 = exp(as.matrix(td2) %*% as.matrix(fin_mod$beta2)),
                        lambda_3 = exp(as.matrix(td3) %*% as.matrix(fin_mod$beta3)))


```


```{r MONTE CARLO PERFORMANCE TESTING}
# Monte Carlo Simulation 
# use this to generate data - https://stats.stackexchange.com/questions/27443/generate-data-samples-from-poisson-regression

n_test_obs <- nrow(final_lambdas)
n_sims <- 100000
set.seed(1)
all_monte_carlos <- as.data.frame(matrix(NA, nrow = n_sims, ncol = 2*n_test_obs))
for(i in 1:n_test_obs) {
  monte_carlo <- rbvpois(n_sims, final_lambdas$lambda_1[i], 
                       final_lambdas$lambda_2[i], 
                       final_lambdas$lambda_3[i])
  all_monte_carlos[, (2*i-1)] <- monte_carlo[, 1]
  all_monte_carlos[, (2*i)] <- monte_carlo[, 2]
}

test_actuals <- tibble(home = test_home, away = test_away) %>%
  mutate(outcome = case_when(
    test_home - test_away == 0 ~ "Draw",
    test_home - test_away > 0 ~ "Win",
    test_home - test_away < 0 ~ "Loss"
  ),
  pred_win_prob = NA,
  pred_loss_prob = NA,
  pred_draw_prob = NA
  )

for(i in 1:n_test_obs) {
  test_actuals[i, "pred_win_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] > 0))/n_sims
  test_actuals[i, "pred_loss_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] < 0)) /n_sims
  test_actuals[i, "pred_draw_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] == 0)) /n_sims  
}

test_actuals <- test_actuals %>%
  mutate(pred_outcome = case_when(
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_draw_prob ~ "Likely Draw",
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_win_prob ~ "Likely Win",
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_loss_prob ~ "Likely Loss"

  ))

# Confusion matrix assuming max_prob is the predicted outcome - bit misleading as performance metric because sometimes probabilities are only diff by 0.05 or so but this will still pick a single outcome. Should find a way to adjust for close wins/losses/draws
confusion_mat <- table(test_actuals$outcome, test_actuals$pred_outcome)

confusion_mat

# # Win accuracy
# confusion_mat[9]/ (confusion_mat[9] +  confusion_mat[6] + confusion_mat[3])
# 
# # Loss accuracy
# confusion_mat[5]/ (confusion_mat[5] +  confusion_mat[2] + confusion_mat[8])
# 
# # Draw accuracy
# confusion_mat[1]/ (confusion_mat[1] +  confusion_mat[4] + confusion_mat[7])
# 
# # Overall accuracy
# (confusion_mat[1] +  confusion_mat[5] + confusion_mat[9])/n_test_obs


# Win accuracy
confusion_mat[6]/ (confusion_mat[3] +  confusion_mat[6])

# Loss accuracy
confusion_mat[2]/ (confusion_mat[2] +  confusion_mat[5])

# Draw accuracy is ZERO

# Overall accuracy
(confusion_mat[2] +  confusion_mat[6])/n_test_obs


```

### Prediction

We need to make the World Cup 2022 Dataset that has the same columns as our model dataset. 


```{r}
#qatar_teams
matches_sched[matches_sched == "USA"] <- "United States"


group_matches <- matches_sched %>% 
  filter(phase == "group matches") %>% 
  rename(hometeam = country1, awayteam = country2)

group_matches
```

Constructed Group Stage Matches Dataset with needed data


```{r}
group_matches <- group_matches %>% full_join(qatar_groupstage_teams, by = c('hometeam'='Team')) %>% 
  full_join(qatar_groupstage_teams, by = c('awayteam'='Team')) %>% 
  mutate(
     offense_differential = Offense.x - Offense.y,
     defense_differential = Defense.x - Defense.y,
     midfield_differential = Midfield.x - Midfield.y,
     fifa_rank_differential = Rank.x-Rank.y,
     points_differential = Points.x - Points.y,
     goalkeeper_differential=Goalkeeper.x - Goalkeeper.y,
     possession_differential=avg_possession.x-avg_possession.y,
     shots_on_target_differential=avg_shotsontarget.x-avg_shotsontarget.y,
     shots_differential=avg_shots.x-avg_shots.y,
     yellow_cards_differential=avg_yellowcards.x-avg_yellowcards.y,
     red_card_differential=avg_redcards.x-avg_redcards.y,
     fouls_differential=avg_fouls.x-avg_fouls.y,
     score_differential=avg_goals.x-avg_goals.y) %>% 
  select(hometeam, awayteam, offense_differential, defense_differential, midfield_differential,
         fifa_rank_differential,points_differential,goalkeeper_differential,possession_differential,
         shots_on_target_differential,shots_differential,yellow_cards_differential,red_card_differential,
         fouls_differential,score_differential)

group_matches

#write_csv(group_matches, "data/final_group_matches.csv")


final_model2_data <- matches_results_2022 %>%
  left_join(group_matches, by = c("country1" = "hometeam", "country2" = "awayteam")) %>%
  mutate(neutral_location = ifelse(country1 == "Qatar" | country2 == "Qatar", FALSE, TRUE)) %>%
  .[1:48, ]

final_model1_data <- final_model2_data %>%
  select(date, country1, country2, country1_score, country2_score, 
         offense_differential, defense_differential, midfield_differential) 
```


## Model 1 2022 preds (orig dataset, poisson)

```{r final_2022_predictions--model-1}
biv_cups_only_nona <- cups_only_nona %>%
  mutate(neutral_location = ifelse(neutral_location == TRUE, 1, 0))

# HOME FIELD COMPENSATION?
n <- nrow(biv_cups_only_nona)

# set.seed(3)
# switch <- sample(1:n, 0.5*n)
# 
# biv_cups_only_nona <- biv_cups_only_nona %>%
#   mutate(hgoals_new  = NA, agoals_new = NA)
# 
# for(i in 1:n) {
#   if(i %in% switch) {
#     biv_cups_only_nona[i, "hgoals_new"] = biv_cups_only_nona[i, "away_team_score"]
#     biv_cups_only_nona[i, "agoals_new"] = biv_cups_only_nona[i, "home_team_score"]
#     biv_cups_only_nona[i, "offense_differential"] = - (biv_cups_only_nona[i, "offense_differential"])
#     biv_cups_only_nona[i, "defense_differential"] = - (biv_cups_only_nona[i, "defense_differential"])
#     biv_cups_only_nona[i, "midfield_differential"] = - (biv_cups_only_nona[i, "midfield_differential"])
#     biv_cups_only_nona[i, "points_differential"] = - (biv_cups_only_nona[i, "points_differential"])
#     biv_cups_only_nona[i, "rank_differential"] = - (biv_cups_only_nona[i, "rank_differential"])
#   }
#   else {
#     biv_cups_only_nona[i, "hgoals_new"] = biv_cups_only_nona[i, "home_team_score"]
#     biv_cups_only_nona[i, "agoals_new"] = biv_cups_only_nona[i, "away_team_score"]
#   }
# }


train_data_biv <- biv_cups_only_nona

#all variables are predictors that have significance based on lasso

#each lambda in fin_mod represents the rate param for home, away, and the 
#correlation between the first two vars

#lambda depends on the beta values (the X coefficient)s 

fin_mod <- lm.bp(l1 = home_team_score~ 
                   offense_differential + defense_differential + midfield_differential,
                 l2 = away_team_score~ offense_differential + defense_differential + midfield_differential,
                 l3 = ~ offense_differential + defense_differential + midfield_differential, 
                 data = train_data_biv)


test_home <- final_model2_data[, "country1_score"] 
test_away <- final_model2_data[, "country2_score"] 


td1 <- final_model1_data %>%
         select(offense_differential, 
                   defense_differential,midfield_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)
td2 <- final_model1_data %>%
         select(offense_differential, 
                   defense_differential,midfield_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)
td3 <- final_model1_data %>%
         select(offense_differential, 
                   defense_differential,midfield_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)

#get final values for lambdas
final_lambdas <- tibble(lambda_1 = exp(as.matrix(td1) %*% as.matrix(fin_mod$beta1)),
                        lambda_2 = exp(as.matrix(td2) %*% as.matrix(fin_mod$beta2)),
                        lambda_3 = exp(as.matrix(td3) %*% as.matrix(fin_mod$beta3)))

n_test_obs <- nrow(final_lambdas)
n_sims <- 100000
set.seed(1)
all_monte_carlos <- as.data.frame(matrix(NA, nrow = n_sims, ncol = 2*n_test_obs))
#draw randomly from the distirbution of the poisson distributions 
for(i in 1:n_test_obs) {
  # [home-away] score prediction so ex: 2-0 or 3-3
  monte_carlo <- rbvpois(n_sims, final_lambdas$lambda_1[i], 
                       final_lambdas$lambda_2[i], 
                       final_lambdas$lambda_3[i])
  all_monte_carlos[, (2*i-1)] <- monte_carlo[, 1]
  all_monte_carlos[, (2*i)] <- monte_carlo[, 2]
}

test_actuals <- tibble(home = test_home, away = test_away) %>%
  mutate(outcome = case_when(
    test_home - test_away == 0 ~ "Draw",
    test_home - test_away > 0 ~ "Win",
    test_home - test_away < 0 ~ "Loss"
  ),
  pred_win_prob = NA,
  pred_loss_prob = NA,
  pred_draw_prob = NA
  )

for(i in 1:n_test_obs) {
  test_actuals[i, "pred_win_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] > 0))/n_sims
  test_actuals[i, "pred_loss_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] < 0)) /n_sims
  test_actuals[i, "pred_draw_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] == 0)) /n_sims  
}

test_actuals <- test_actuals %>%
  mutate(pred_outcome = case_when(
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_draw_prob ~ "Likely Draw",
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_win_prob ~ "Likely Win",
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_loss_prob ~ "Likely Loss"

  ))

# Confusion matrix assuming max_prob is the predicted outcome - bit misleading as performance metric because sometimes probabilities are only diff by 0.05 or so but this will still pick a single outcome. Should find a way to adjust for close wins/losses/draws
confusion_mat <- table(test_actuals$outcome, test_actuals$pred_outcome)

confusion_mat

# Draw accuracy still zero bruh

# win accuracy:
confusion_mat[6]/(confusion_mat[3] + confusion_mat[6])

# Loss accuracy
confusion_mat[2]/(confusion_mat[2] + confusion_mat[5])

# Overall accuracy
(confusion_mat[2] + confusion_mat[6]) /n_test_obs
```


## Model 2 2022 preds (new dataset)



```{r final_2022_predictions--model_2, warning=FALSE}
#all the differentials
biv_cleaned_matches<- cleaned_matches %>%
  mutate(neutral_location = ifelse(neutral_location == TRUE, 1, 0))


#final model2 data is the training data 
test_home <- final_model2_data[, "country1_score"] 
test_away <- final_model2_data[, "country2_score"] 

#getting three datasets from this, one for each matrix of X for the biv poisson model
#they also include intercept
td1 <- final_model2_data %>%
         select(fifa_rank_differential, offense_differential,goalkeeper_differential,
          neutral_location,
       shots_on_target_differential,shots_differential,yellow_cards_differential,fouls_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)
td2 <- final_model2_data %>%
         select(fifa_rank_differential, offense_differential,goalkeeper_differential,
          neutral_location, 
       shots_on_target_differential,shots_differential,yellow_cards_differential,fouls_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)
td3 <- final_model2_data %>%
         select(fifa_rank_differential, offense_differential,goalkeeper_differential,
          neutral_location,
       shots_on_target_differential,shots_differential,yellow_cards_differential,fouls_differential) %>% 
  mutate(int_col = rep(1,nrow(.))) %>% 
  relocate(int_col)

#same as above
train_data_biv <- biv_cleaned_matches


#not split... make train data
fin_mod <- lm.bp(l1 = home_team_score~ fifa_rank_differential + offense_differential + goalkeeper_differential +
                   neutral_location+ shots_on_target_differential + shots_differential+ yellow_cards_differential 
                 +fouls_differential,
                 l2 = away_team_score~ fifa_rank_differential + offense_differential + goalkeeper_differential +
                   neutral_location+ shots_on_target_differential + shots_differential+ yellow_cards_differential +fouls_differential,
                 l3 = ~ fifa_rank_differential + offense_differential + goalkeeper_differential +
                   neutral_location+ shots_on_target_differential + shots_differential+ yellow_cards_differential +fouls_differential, 
                 data = train_data_biv)


# ok multiply
final_lambdas <- tibble(lambda_1 = exp(as.matrix(td1) %*% as.matrix(fin_mod$beta1)),
                        lambda_2 = exp(as.matrix(td2) %*% as.matrix(fin_mod$beta2)),
                        lambda_3 = exp(as.matrix(td3) %*% as.matrix(fin_mod$beta3)))


n_test_obs <- nrow(final_lambdas)
n_sims <- 100000
set.seed(1)
all_monte_carlos <- as.data.frame(matrix(NA, nrow = n_sims, ncol = 2*n_test_obs))
for(i in 1:n_test_obs) {
  monte_carlo <- rbvpois(n_sims, final_lambdas$lambda_1[i], 
                       final_lambdas$lambda_2[i], 
                       final_lambdas$lambda_3[i])
  all_monte_carlos[, (2*i-1)] <- monte_carlo[, 1]
  all_monte_carlos[, (2*i)] <- monte_carlo[, 2]
}

test_actuals <- tibble(home = test_home, away = test_away) %>%
  mutate(outcome = case_when(
    test_home - test_away == 0 ~ "Draw",
    test_home - test_away > 0 ~ "Win",
    test_home - test_away < 0 ~ "Loss"
  ),
  pred_win_prob = NA,
  pred_loss_prob = NA,
  pred_draw_prob = NA
  )

for(i in 1:n_test_obs) {
  test_actuals[i, "pred_win_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] > 0))/n_sims
  test_actuals[i, "pred_loss_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] < 0)) /n_sims
  test_actuals[i, "pred_draw_prob"] <- 
    (sum(all_monte_carlos[, (2*i - 1)] - all_monte_carlos[, (2*i)] == 0)) /n_sims  
}

test_actuals <- test_actuals %>%
  mutate(pred_outcome = case_when(
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_draw_prob ~ "Likely Draw",
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_win_prob ~ "Likely Win",
    pmax(pred_win_prob, pred_loss_prob, pred_draw_prob) == pred_loss_prob ~ "Likely Loss"

  ))

# Confusion matrix assuming max_prob is the predicted outcome - bit misleading as performance metric because sometimes probabilities are only diff by 0.05 or so but this will still pick a single outcome. Should find a way to adjust for close wins/losses/draws
confusion_mat <- table(test_actuals$outcome, test_actuals$pred_outcome)

confusion_mat

# Win accuracy
confusion_mat[9]/ (confusion_mat[9] +  confusion_mat[6] + confusion_mat[3])

# Loss accuracy
confusion_mat[5]/ (confusion_mat[5] +  confusion_mat[2] + confusion_mat[8])

# Draw accuracy
confusion_mat[1]/ (confusion_mat[1] +  confusion_mat[4] + confusion_mat[7])

# Overall accuracy
(confusion_mat[1] +  confusion_mat[5] + confusion_mat[9])/n_test_obs


```




