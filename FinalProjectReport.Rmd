---
title: "Predicting Sports Bets within the FIFA 2022 World Cup"
author: "Aaditya Warrier, Sean Li, Christina Yoh, Brian Janger"
output: pdf_document
urlcolor: blue
geometry: margin = 2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE)
```

```{r load-libraries}
# PUT ALL LOADED LIBRARIES HERE
library(tidyverse)
library(knitr)
#library(kableExtra)
library(patchwork)

```

```{r read-data}
# READ IN ANY DATASETS HERE
# MUTATE DATSETS AS NECESSARY HERE
matches <- read_csv("data/cleaned_matches.csv")

```


```{r final-model, results='hide'}
# this file contains all relevant modelling code needed for this doc to run
source("all_model_code.R")
```

# Introduction

The FIFA World Cup is the most important international soccer tournament in the world, bringing in over 5 billion projected viewers across the 29 day tournament. It is held every four years and brings together the best national teams from countries around the globe to compete for the title of world champions. Not only does the World Cup provide an opportunity for players to showcase their skills on the biggest stage, it also generates a huge amount of interest and excitement (and thus revenue), and provides people from all over the world an opportunity to come together and celebrate their love of soccer, fostering a sense of global unity and understanding.

For a subset of the followers of the World Cup, sports betting has become a prominent part of the experience. The sports betting industry is a large and growing market that involves people placing bets on the outcome of various sports events. This can include bets on individual games or on the overall results of a season or tournament. According to Bloomberg, a total of $35 billion will be wagered on the 2022 FIFA World Cup, a 65% increase on the previous World Cup. 

An integral part of sports betting is the usage of statistics, as it can provide valuable information about the likelihood of certain outcomes in a given game or match. By using statistics, bettors can analyze the true risk on various bets (as opposed to a sportsbook's "odds") and make more informed decisions about which bets to place, giving bettors a better chance of winning and achieving profitable returns.

In short, the goal of our project is to build a predictive model for the 2022 World Cup games using historical international football results and FIFA team rankings in order to provide sports bettors valuable information about the probability of certain outcomes in this year's World Cup. We hope to predict goal line bets (point spread/goal differential) as well as 3 way money-line (draw, home win, and away win) bets from the group stage, comparing the odds of respective matches with the odds given by sportsbooks to determine which bets are more likely to be profitable then the odds say.

The dataset we use is a set of thousands of international soccer matches from June 2002 to June 2021, with metrics including team FIFA rank, team FIFA points, match results, offense/defense/midfield score metrics and more. We will first use a Poisson regression model on both home and away team scores to predict score distribution for each team respectively, with a lasso penalty to select significant predictor variables and reduce collinearity. Using these relevant predictors, we will then fit a bivariate Poisson model that takes into account the dependency between home and away team goal distributions. Since we have a small number of goals, Poisson regression makes sense as it is intended for response variables that take on small, positive values. Getting results that are probabilistic distributions are important in our case because sports betters are interested in the distribution of results in order to be able to quantify their risk.

# Data
Our analysis utilized a few different datasets, which were combined (and later cleaned) into one final dataset. The main dataset was found on [GitHub](https://github.com/martj42/international_results), which gathered data from [Wikipedia](https://en.wikipedia.org/wiki/Special:Search?go=Go&search=soccer+results&ns0=1), the [Rec.Sport.Soccer Statistics Foundation](rsssf.com) (a group which "strives to be the most comprehensive and complete" archive of soccer statistics), and individual soccer team websites. It features the results of 44,341 international soccer matches between 1872 (the year of the first official international match) and 2022.

We also used three other datasets to give us the predictor variables we need to successfully analyze the results and scores of international soccer matches. These included [FIFA World Rankings](https://www.fifa.com/fifa-world-ranking/men?dateId=id13792) scraped from 2002 onwards, [FIFA Player and Team Data](https://www.kaggle.com/datasets/stefanoleone992/fifa-22-complete-player-dataset), which details the ratings, positions, and other metrics of individual players in the FIFA video game series from the 2015 to 2022 versions of the game, and  [FIFA World Cup Match Stats](https://www.kaggle.com/datasets/kaito510/fifa-world-cup-match-stats), which tells us additional game specific results like shots on target, possession, red/yellow cards etc. 


## Data Cleaning

In order to combine these datasets into a usable one, we first had to clean the data. Upon merging all of the relevant datasets together for the international matches, we discovered that a lot of these matches had non-existent values for box scores or FIFA ratings. We wanted to be able to include all of these potential predictors in our model diagnostics, so we elected to remove these observations from the model. This led to us getting a dataset of mostly recent international matches (as box score data was not widely recorded in the world of soccer until the 2010s).

Our final dataset held data for 786 international matches, including box score data for each team. To make the creation of a predictive model easier, we decided to combine data for each team into a "differential" metric, which found the difference between a statistic for the home team and that same statistic for the away team. Our final set of predictors included FIFA goalkeeper rating differential, FIFA defense rating differential, FIFA midfield rating differential, FIFA offense rating differential, percentage of possession differential, shots taken differential, shots on target differential, fouls differential, yellow cards differential, red cards differential, FIFA team ranking differential, whether the match was played at a neutral stadium (i.e. neither team was playing in their home stadium), and the teams playing in the match. Since we would not have in game predictors such as shots on target, fouls, yellow/red cards, before a match starts, we computed the averages for the team's past 5 games. For our response variables, we have the home team's score in the match, the away team's score in the match, the computed score differential (home team score minus away team score), and a categorical outcome of the game, where matches were assigned one of three outcomes: the home team winning, the home team losing, and the match ending in a draw (note that for neutral matches, a team is randomly assigned to be the home team).

For our predictor variables above, it is important to note that a positive differential value does not always indicate a good outcome for the home team - for example, a positive shots on target differential indicates that the home team was able to place more shot attempts on the goal than the away team, which is a positive outcome. However, a positive fouls (or yellow and red cards) differential indicates that the home team committed more penalties, which is a negative outcome. This is an important observation to keep in mind when observing our graphs and models featured later in this report.

Lastly, we also had to create the World Cup 2022 Dataset that has the same columns as our model dataset in order to use it as a final test set. In order to do this, we acquired a CSV with the group stage teams and their FIFA point metrics (offense, defense, midfield, rank, points, goalkeeper), then took averages of the last 5 games as values for other predictors (avg goals, avg shots on target, etc). The reason we had to do this is because typically, in the case of sports betting, the game hasn't occurred so those metrics would not be available yet; thus, we are taking the averages as the inputs. Lastly, using these values, we created a dataset that has the same columns as our model dataset by computing differentials as the difference in scores between the home and away team. 

# Exploratory Data Analysis

To begin our analysis, we first looked at the distribution of the score differentials and the game outcomes. Since the outcomes of the international matches is a categorical variable that can only take on three values, we show a table approach:

```{r}
t1 <- matches %>%
  count(home_team_result) %>%
  rename("Home Team Result" = home_team_result,
         Count = n)
knitr::kable(t1, caption = "International Match Results") #%>%
  #kable_styling(position = "center",
  #              latex_options = "HOLD_position")
```

We see that the home team appears to win more often than any other outcome - this will be an important thing to factor into our model as it could accidentally skew outcomes in favor of the home team. Diving further into these games, we see a histogram of the score differentials of all the matches in our dataset:

```{r fig.width=5,fig.height=3}
ggplot(data = matches, aes(x = score_differential)) +
  geom_bar(stat = "count") +
  geom_vline(xintercept = mean(matches$score_differential),
             color = "red") +
  geom_vline(xintercept = median(matches$score_differential),
             color = "blue") +
  labs(x = "Score Differential",
       y = "Count",
       title = "Score Differential Distribution of International Matches",
       subtitle = "Score Differential = Home Team Score - Away Team Score")
```

The score differentials range from -6 to 7, and it appears that the distribution of score differentials appears to be close to normally distributed. This graph could indicate that if a team were to win or lose, it is most likely by only a goal or two, as those outcomes make up the bulk of the distribution. The median (blue line) of the score differentials is zero and the mean (red line) of the score differentials is `r round(mean(matches$score_differential),3)`.

Next, we wanted to see if we could associate any of the predictors visually with the outcome of the game. The predictor variable that appeared to have the largest effect on the goal differential was the shots on target differential (note that while the response variable is not categorical, we can still interpret it as such with observations on the dotted red line indicating draws, observations above the red line indicating home team wins, and observations below the red line indicating home team losses):

```{r fig.width=5,fig.height=3}
ggplot(data = matches, aes(x = shots_on_target_differential, y = score_differential)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method="lm") +
  geom_hline(yintercept = 0, linetype = 2, color = "red") +
  labs(x = "Shots on Target Differential",
       y = "Goal Differential",
       title = "Game Outcome Related to Difference in Shots on Target")
```

This made sense to us as an increase in the number of shots on target relative to the other team indicates that there are more opportunities for a team to score. Therefore, an increase in the shots on target differential indicates that they are more likely to win (and win my more goals). However, while there does appear to be a general trend for win probability, we can see that the distribution of goal differential when we hold this differential constant is still very wide - for example, when we hold the shots on target differential at 5, we had observations ranging from a home team victory by 4 goals to a home team loss by 2 goals, which is a very wide range.

We also saw similar trends (but to a lesser extent) with each of the rating metrics from the FIFA series, shown below:

```{r}
p1<-ggplot(data = matches, aes(x = goalkeeper_differential, y = score_differential)) +
  geom_point(alpha=0.3) +
  geom_smooth(method="lm") +
    geom_hline(yintercept = 0, linetype = 2, color = "red") +
  labs(x = "Goalkeeper Rating Diff",
       y = "Score Differential")

p2<-ggplot(data = matches, aes(x = midfield_differential, y = score_differential)) +
  geom_point(alpha=0.3) +
  geom_smooth(method="lm") +
    geom_hline(yintercept = 0, linetype = 2, color = "red") +
  labs(x = "Midfield Rating Diff",
       y = "Score Differential")

p3<-ggplot(data = matches, aes(x = offense_differential, y = score_differential)) +
  geom_point(alpha=0.3) +
  geom_smooth(method="lm") +
    geom_hline(yintercept = 0, linetype = 2, color = "red") +
  labs(x = "Offense Rating Diff",
       y = "Score Differential")

p4<-ggplot(data = matches, aes(x = defense_differential, y = score_differential)) +
  geom_point(alpha=0.3) +
    geom_hline(yintercept = 0, linetype = 2, color = "red") +
  geom_smooth(method="lm") +
  labs(x = "Defense Rating Diff",
       y = "Score Differential")

(p1+p2)/(p3+p4)
```

We see positive relationships with each of these potential predictors and the goal differential. These trends are something interesting we would like to explore in our numerical and probabilisitic models. However, the similarly-distributed scatterplots and lines of best fit could indicate a possible instance of multicollinearity between these predictors - this is something we must explore and do our best to avoid when fitting our models.

We briefly explore this potential multicollinearity a little further:

```{r fig.height = 3, fig.width = 5}
ggplot(data = matches, aes(x = offense_differential,
                           y = defense_differential,
                           color = home_team_result)) +
  geom_point(alpha = 0.3) +
  labs(x = "Offense Rating Diff",
       y = "Defense Rating Diff",
       color = "Home Team Outcome",
       title = "Possible Multicollinearity in Data",
       subtitle = "Rating Differentials Appear to Increase With Each Other")
```

We can see from the above scatterplot that as a team's offense improves over another team's offense, it appears that their defense will generally improve over the other team as well (and vice versa). This shows potential collinearity of our predictors, showing that a team is generally holistically better if they are to win matches. Furthermore, we see from this plot that while the data is clearly not linearly separable, we can see groupings of the win and loss observations, meaning that differentiating between these two categories will be more than possible. However, we see that the draw outcomes tend to overlap with both of these groups, indicating that predicting matches that end in a draw is likely very difficult as they have a much more volatile and inconsistent grouping in our data.

# Methodology

## Model selection and validation

We initially chose to use a GLM-based Poisson regression model to predict goals for home and away teams in each match, as Poisson regression is most appropriate when the response is a discrete count, as is the case for goals scored in a match. We wanted to perform both regularization and variable selection, as our dataset had a very large number of correlated predictors and we suspected that performance could be predicted using a much sparser set of variables; therefore, we introduced a LASSO penalty using the glmnet package, and 5-fold cross validated for the optimal value of lambda. However, we quickly realized that since the outcome of a soccer game is very dependent and how two specific teams interact with each other, we could not use univariate models that would predict a team's score in a vacuum. Hence, we finally decided to use a bivariate poisson regression model to account for these possible correlations.

The general form of this model is as follows (Kallis & Ioannis) :

Consider random variables $X_k$, K = 1, 2, 3 which follow independent Poisson distributions with parameters $\lambda_k$, respectively. Then random variables X and Y are given by $X = X_1+X_3$ and $Y = X_2+X_3$ and jointly follow a bivariate Poisson distribution. So, E(X) = $\lambda_1 + \lambda_3$ and E(Y) = $\lambda_2 + \lambda_3$. In our case, X represents goals scored by the home team, while Y represents goals score by the away team.

When we add covariates, we then have:

$$(X_i, Y_i) \sim BP(\lambda_{1i}, \lambda_{2i}, \lambda_{3i})$$
$$log(\lambda_{1i}) = w_{1i}^T\beta_1$$
$$log(\lambda_{2i}) = w_{2i}^T\beta_2$$
$$log(\lambda_{3i}) = w_{3i}^T\beta_3$$

where i = 1, . . . , n, is the observation number, $w_i$ is a vector of predictors for the i-th observation used to model $\lambda_{ki}$, and $\beta_k$ denotes the corresponding vector of regression coefficients K = 1, 2, 3.

Upon research, we discovered that bivariate models with LASSO regularization have not been invented as of yet (or at least not in a form that is easy to implement). To simulate the potential benefits of this framework as much as possible, we decided to screen our variables using the results of our univariate LASSO models, choosing the sparser set of variables among the home and away models as final predictors in the bivariate model.


During this process, we tried a number of other models and datasets to build the most robust model - this included a multinomial model that predicted outcomes, as well as a bivariate Poisson model on a far larger dataset that contained  possession stats, shot accuracy etc. for individual matches, which we could use to calculate running averages for each team. However, when comparing accuracy using misclassfication error from Monte Carlo draws (this will be elucidated upon shortly), using 5-fold cross validation on our training set as well as predicting outcomes for the test set (i.e 2022 games), we found that our original dataset and model worked best and were the most statistically robust.

## Assumptions

Clearly, independence cannot be satisfied here as each team's result in a match is not independent of their result in another; however, for the purposes of our analysis, we can assume that our fairly large sample size can counter this to some extent and stay. Caveating this, the two primary assumptions that need to be satisfied are:

1. Ensure that the response is a count, and that these counts are Poisson distributed. This means mean should be roughly equal to variance for goals scored across all of our historical matches we use as a training set.
2. There are linear relationships between the log of each rate parameter (i.e $\log{\lambda_k}$) and changes in predictor variables. 

The first of these is undoubtedly the most important - we can examine the mean and variance of historical goals, as well as visualize their distribution below (it is self-evident that the response is a count):

```{r}
# biv_cups_only_nona %>%
#   group_by(home_team) %>%
#   summarize(mean_score = mean(home_team_score), var_score = var(home_team_score))
# 
# biv_cups_only_nona %>%
#   group_by(away_team) %>%
#   summarize(mean_score = mean(home_team_score), var_score = var(home_team_score))

table1 <- biv_cups_only_nona %>%
  summarize("Mean Score" = mean(home_team_score), "Score Variance" = var(home_team_score))

table2 <- biv_cups_only_nona %>%
  summarize("Mean Score" = mean(away_team_score), "Score Variance" = var(away_team_score))
knitr::kable(table1, caption = "Goal Metrics for Home Team")
knitr::kable(table2, caption = "Goal Metrics for Away Team")

par(mfrow = c(1,2))
hist(biv_cups_only_nona$home_team_score, main = "Home Goals Distribution", xlab = "Goals")
hist(biv_cups_only_nona$away_team_score, main = "Away Goals Distribution", xlab = "Goals")

```

We see that for both home and away goals, mean and variance across games are nearly equal, while the distributions themselves also look roughly Poisson distributed. We can assume this condition is satisfied.

The second assumption is strongly satisfied for $\lambda_1$ and $\lambda_2$, while slightly less strongly satisfied for $\lambda_3$. See Figure 1 in Appendix for details.

## Creating Moneyline Estimations

As sports bettors are generally interested in a spread/probabilistic outlook on game outcomes to make an informed decision, we decided to run 100,000 Monte Carlo simulations of our games to obtain estimated odds/probabilities of each game closing with a home team win, loss or draw - this is the "3-way moneyline" referred to in our introduction. We did this by drawing randomly from bivariate Poisson distributions, whose parameters were outputted/estimated by our regression model based on predictor values. Although moneyline estimations are generally presented in an odds-based format, we chose to compute probabilities instead as this is more intuitive from a statistical standpoint. However, these can easily be converted to odds by the following formula:

$\text{Negative Odds: Probability} = \frac{-1\times\text{odds}}{-1\times \text{odds} +100}$

$\text{Positive Odds: Probability} = \frac{100}{\text{odds} +100}$

We did try computing goal-line estimations as we had initially hoped to; however, we had limited success with its accuracy and also could not find any estimations online that we could compare against, so we chose to exclude them from this report.

# Model Results


## Interpretation

```{r}
kable(fin_mod$coefficients)
```

Our final predictors for our bivariate Poisson model were `defense_differential`, `midfield_differential`, and `offense_differential`, and all other predictors were determined to not be statistically significant in the model, which was a surprise considering our trends found in the EDA. These predictors suggest that the FIFA rankings of the players on the respective teams are the most indicative in predicting match score outcomes. For every one unit the home defense is better than the away team, we can expect the rate parameter for home goals to be multiplying by a factor of $e^{0.0237813-0.0890923}$ = 0.937. For every one unit the home midfield is better than the away team, we can expect the rate parameter for home goals to be multiplying by a factor of $e^{0.0095639 +0.1558049}$ = 1.18. For every one unit the home offense is better than the away team, we can expect the rate parameter for home goals to be multiplying by a factor of $e^{0.0133452-0.0253598}$ = 0.988. 

For every one unit the home defense is better than the away team, we can expect the rate parameter for away goals to be multiplied by a factor of $e^{-0.0044015 -0.0044015}$ = 0.991. For every one unit the home midfield is better than the away team, we can expect the rate parameter for away goals to be multiplied by a factor of $e^{-0.02504881+0.1558049}$ = 1.17. For every one unit the home offense is better than the away team, we can expect the rate parameter for away goals to be multiplied by a factor of $e^{-0.0237410-0.0253598}$ = 0.952. 



From the model coefficients, it's interesting to note that some of the conclusions for the home and away team goals are seemingly contradictory - for example, our model predicted that for every one unit the home midfield is better than the away team, we can expect the rate parameter for home goals to be multiplying by a factor of $e^{0.0095639 +0.1558049}$ = 1.18, but also predicted that for every one unit the home midfield is better than the away team, we can expect the rate parameter for away goals to be multiplied by a factor of $e^{-0.02504881+0.1558049}$ = 1.17. However, since 1.18 is still marginally greater than 1.17, we can say that the goal differential (home-away) will still be positive - in the case that home midfield is one unit better than the away team, the rate parameter for home goals is greater than the rate parameter for away goals. The coefficients for both defense and offense seem a little bit counterintuitive, as they state that as defense/offense score increase, the rate parameter for home goals decreases, implying that teams should weaken their defense/offense to score more, which doesn't really make sense. However, a possible interpretation is that we can look at a focus on defense, midfield, and offense as a spectrum -- the more a team focuses on defense, to less they focus on offense, and thus may be less likely to score, or vice versa. 

For sports bettors, the main takeaway is that a team's player composition - their defense, midfield, and offense player rankings - are the most important metrics to investigate (over other metrics like shots or saves in past games) when the results of a matchup. In addition, the composition of a team and their respective strengths in defense, midfield, and offense, is also indicative of how many goals they end up scoring compared to the other team and thus the final outcome of the game. 

## Estimated Moneyline Probabilities 

Based on our model, we can generate moneyline predictions for all matches as below; as mentioned earlier, we chose to stick with probabilities for a more intuitive understanding of match outcomes from a statistical point of view. 

```{r}
kable(test_actuals %>%
  select(match_num, home_team, away_team, pred_win_prob, pred_loss_prob, pred_draw_prob), digits = 3, 
  col.names = c("Match Number", "Home Team", "Away Team", "Win Prob", "Loss Prob", "Draw Prob"))
```

```{r include = FALSE}
median(abs(test_actuals$pred_win_prob - results_and_odds2$winProb))
median(abs(test_actuals$pred_loss_prob - results_and_odds2$loseProb))
median(abs(test_actuals$pred_draw_prob - results_and_odds2$drawProb))
```


A good barometer that our probabilities are generally in the right direction is to comparing them to odds marked by professional sports books. Using an aggregation of odds from OddsPortal (a popular sports betting website) and converting them to probabilities, we found that the median difference in home team win probabilities was only about 0.059, with the medians for loss and draw being 0.041 and 0.026 roughly. 

## Predictive Accuracy

Finally, based on our model's probabilities, we were wanted to see how often our model's most likely outcome for a given match would be the correct one. We calculated our confusion matrix below:

```{r}
kable(confusion_mat, caption = "Confusion Matrix for Model")
```

This implied a home team win accuracy of about `r round(confusion_mat[6]/(confusion_mat[3] + confusion_mat[6]), 2) * 100`%, a home team loss/away team win accuracy of about `r round(confusion_mat[2]/(confusion_mat[2] + confusion_mat[5]), 2) * 100`%, and an overall accuracy of about `r round((confusion_mat[2] + confusion_mat[6]) /n_test_obs, 2) *100`% (getting 26 of the 48 group stage matches correct). Note that our model did not predict any draws at all, despite there being 10 draws across 48 games, which hence put our draw accuracy at zero. Although this last finding seems problematic, it must be acknowledged that draws are notoriously difficult to predict accurately - in fact, using the aggregation of odds from OddsPortal to predict outcomes leads to exactly the same result:

```{r}
kable(confusion_mat_books, caption = "Confusion Matrix for Sports Books")
```

Clearly, no "Likely Draw" column exists here either. We can also calculate accuracies as above: win accuracy would be `r round(confusion_mat_books[6]/(confusion_mat_books[3] + confusion_mat_books[6]),2) * 100`%, loss accuracy `r round(confusion_mat_books[2]/(confusion_mat_books[2] + confusion_mat_books[5]),2) * 100`% and overall accuracy `r round((confusion_mat_books[2] + confusion_mat_books[6]) /n_test_obs, 2) * 100`%. We see that our model has performed somewhat better than sports books odds for home team losses/away team wins, the ultimate effect and implications of which will be discussed briefly in our conclusion.

# Conclusion 

To summarize our work - our model tackles the most important bet in soccer, the 3-way moneyline (win, loss, draw). For the group stage in the 2022 World Cup, we came up with relative probabilities for each possible match outcome based on modeling the number of home goals and away goals on a bivariate Poisson model. We further analyzed our model coefficients and what they said about drivers of performance in soccer, as well as their implications for sports bettors. Finally, we compared our model's average accuracy over all matches to the accuracy implied by sports books odds. 

In closing out our analysis, we wanted to see if our model could actually make us money on average; with payouts based on the pregame moneyline odds taken from OddsPortal, we chose to simply bet on the most likely outcome for each match based on our model. Of course, this is not always the most optimal betting strategy - importantly, the objective of the model is to mark odds as accurately as possible for each match, not tell bettors who to bet on - but it would give us an idea of how profitable the model would be if we were to make the safest bets possible.

For moneyline bets, our model would have obtained a net profit of -\$327, i.e it would lose 327 dollars over all 48 bets across group stage matches. This is assuming one placed a flat \$100 bet for each match on the most likely line as predicted by our model, as previously mentioned. Furthermore, one can apply a number of more complex betting strategies given a set of odds our model generates, but that is beyond the scope of the project. However, while our model lost money, it still **outperforms** a bettor who places the same 100 dollars on the most likely line as indicated by the sports books' odds, who would lose roughly \$2600. This makes perfect sense - according to most sports betting experts, the optimal betting strategy is to bet on underdogs at least some of the time i.e bet on less likely outcomes in at least some matches. This is because lines for unlikely outcomes have far greater payout, so while betting on likely outcomes would probably end up in making the right call more often, this does not ensure long-term profit. However, it is reassuring all the same that our model's had odds and calls marked more accurately for these "safe" bets. Furthermore, while our model did lose money (more specifically, it lost \$327 on \$4800 of total bets), it did so without the incorporation of an optimized betting strategy, where bet values could differ depending on the difference in our estimated probability and the sportsbook's implied probability. This strategy is out of the scope of this project, but optimizing the betting strategy from our model outcomes could reduce this loss even further (or bring the model into profit). The percentage loss was 6.8% of money betted, which is comparable to a sportsbook's general "house edge" of about 4 to 5 percent - if sportsbooks had no edge on the gambler, our model would have likely lost just less than two percent of money betted.

One intuitive way to apply our findings for future matchups is to spot significant differences between the sports book odds and the ones our model puts out. A significant difference could mean that we see a value bet in a less likely event according to a sports book but more likely according to the model. For example: Let's take a look at the Ecuador - Senegal match which had the pregame line of +148, +208, +223 for an Ecuador win, draw, and loss, respectively. That translates the most likely outcome being an Ecuador win, whereas our model had probabilities of roughly 0.32, 0.28, 0.38, translating to predicting a Ecuador loss, which did happen as Ecuador lost to Senegal 1-2. This would be an indicator where our model determined that the estimated probability of an outcome was higher than what the sportsbook's odds implied, meaning that our model suggests we should place a bet on this outcome as the expected profit would be positive (assuming an accurate model).

Most of our work's limitations stem from the nature of the problem we are trying to solve - sports are inherently hard to predict, which is why any model we built did not have great accuracy. If building high performing models was easy, then sports books would simply go out of business! Much of the intrigue of sports betting is indeed knowing when to make the call on the underdog, something our model simply cannot capture. Furthermore, it is difficult to take into account the interaction between two specific teams, as they prepare customized game plans that differ based upon opponent that are not released to the public. These intangibles were not accounted for by the predictors for the models were built. Sports bettors should heed also caution when using our model (or any model) to accurately predict draws; as we saw before, it predicted none of the 10 draws across 48 matches correctly. This limitation is likely linked to the low-scoring nature of soccer and the fact that draws never appeared to be the most likely outcome in both sportsbooks' implied match outcome probabilities and our model's estimated probabilities. Future work may include building models to target other bets, such as over/under on total goals scored or various team/player prop bets, and finding other statistically siginificant predictors which can be used to further predict the outcome of soccer matches (preferably uncovering which statistics are most likely to correlate to matches ending in a draw, which was the weakest area of our model). 


# Appendix

Figure 1

```{r}
assumption <- tibble(lambda1 = fin_mod$lambda1,
                     lambda2 = fin_mod$lambda2,
                     lambda3 = fin_mod$lambda3,
                     offense_diff = biv_cups_only_nona$offense_differential,
                     defense_diff = biv_cups_only_nona$defense_differential,
                     midfield_diff = biv_cups_only_nona$midfield_differential)
p1 <- ggplot(data = assumption, 
       aes(y = log(lambda1), 
             x = offense_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Offense Differential", 
       y = "Logged Lambda 1")
p2 <- ggplot(data = assumption, 
       aes(y = log(lambda1), 
             x = defense_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Defense Differential", 
       y = "Logged Lambda 1")
p3 <- ggplot(data = assumption, 
       aes(y = log(lambda1), 
             x = midfield_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Midfield Differential", 
       y = "Logged Lambda 1")

p4 <- ggplot(data = assumption, 
       aes(y = log(lambda2), 
             x = offense_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Offense Differential", 
       y = "Logged Lambda 2")
p5 <- ggplot(data = assumption, 
       aes(y = log(lambda2), 
             x = defense_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Defense Differential", 
       y = "Logged Lambda 2")
p6 <- ggplot(data = assumption, 
       aes(y = log(lambda2), 
             x = midfield_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Midfield Differential", 
       y = "Logged Lambda 2")

p7 <- ggplot(data = assumption, 
       aes(y = log(lambda3), 
             x = offense_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Offense Differential", 
       y = "Logged Lambda 3")
p8 <- ggplot(data = assumption, 
       aes(y = log(lambda3), 
             x = defense_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Defense Differential", 
       y = "Logged Lambda 3")
p9 <- ggplot(data = assumption, 
       aes(y = log(lambda3), 
             x = midfield_diff)) + 
  geom_point() + 
  geom_smooth() + 
  labs(x = "Midfield Differential", 
       y = "Logged Lambda 3")

(p1 + p2 + p3)/(p4+p5+p6)/(p7+p8+p9)
```


# Citations 

“The Introduction Page of the RSSSF -- the Rec.sport.soccer Statistics Foundation.” The Introduction Page of the RSSSF -- The Rec.Sport.Soccer Statistics Foundation., https://rsssf.org/. 

Karlis, Dimitris, and Ioannis Ntzoufras. “Bivariate Poisson and Diagonal Inflated Bivariate Poisson Regression Models in R.” Journal of Statistical Software, vol. 14, no. 10, Sept. 2005, https://doi.org/10.18637/jss.v014.i10. 

Leone, Stefano. “FIFA 22 Complete Player Dataset.” Kaggle, 1 Nov. 2021, https://www.kaggle.com/datasets/stefanoleone992/fifa-22-complete-player-dataset. 

martj42. “Martj42/international_results.” GitHub, https://github.com/martj42/international_results. 
“Men's Ranking.” FIFA, https://www.fifa.com/fifa-world-ranking/men?dateId=id13792. 

“Search Results.” Wikipedia, Wikimedia Foundation, https://en.wikipedia.org/wiki/Special:Search?go=Go&amp;search=soccer%2Bresults&amp;ns0=1. 

“World Cup 2022 Results &amp; Historical Odds.” Oddsportal.com, LiveSport, https://www.oddsportal.com/soccer/world/world-cup-2022/results/. 
